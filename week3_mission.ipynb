{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. 본격적으로 Numpy와 친해지기 위해서 다양한 연산을 연습해볼 예정입니다. 무작위의 데이터를 가 진 5x3의 행렬을 가지는 numpy array와 3x2 행렬을 가지는 numpy array를 만든 후 행열곱 연산을 진행해보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05981584 0.31801188]\n",
      " [0.79174208 1.06746217]\n",
      " [0.37446177 0.60219451]\n",
      " [0.70699854 1.06464762]\n",
      " [0.13449509 0.54418628]] (5, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr1 = np.random.rand(5,3)\n",
    "arr2 = np.random.rand(3,2)\n",
    "\n",
    "dot = arr1.dot(arr2)\n",
    "\n",
    "print(dot, dot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 두번째로는 numpy에서 자주 사용하는 concatenate 연산에 대한 미션을 수행해보겠습니다. 이제 Numpy에서 사용하는 2개의 numpy array가 있을때, 두 numpy array의 concatenate 연산을 구해보세요.  \n",
    "\n",
    "- axis는 0, 1 두개로 연산한 결과를 출력해보세요.\n",
    "- 각 데이터가 어떤 형태로 더해지는지 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  7.]\n",
      " [ 9. 11.]\n",
      " [ 2.  4.]\n",
      " [ 6.  8.]]\n",
      "[[ 5.  7.  2.  4.]\n",
      " [ 9. 11.  6.  8.]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[5,7], [9,11]], float)\n",
    "arr2 = np.array([[2,4], [6,8]], float)\n",
    "\n",
    "concat_1 = np.concatenate((arr1, arr2), axis=0)\n",
    "concat_2 = np.concatenate((arr1, arr2), axis=1)\n",
    "\n",
    "print(concat_1)\n",
    "print(concat_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. 3번부터 5번까지의 미션는 Numpy를 이용해서 정답값을 예측해보는 linear regression을 구현해 보는 미션입니다. 첫번째 단계로 데이터를 준비해보도록 하겠습니다. 아래와 같이 데이터가 주어져있을 때, 경사하강법을 위한 데이터를 분리해보세요.\n",
    "\n",
    "- 주어진 xy 데이터를 이용해서 학습과 정답 데이터를 준비해보세요. <br>\n",
    "*추가 수정* 문제에서 주어진 xy에서 대괄호를 한 번 더 묶어주어야 문제 해결이 가능합니다.\n",
    "(차원 관련)  (np.array([[1., 2., 3., 4., 5., 6.], [10., 20., 30., 40., 50., 60.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6.] (6,)\n",
      "[10. 20. 30. 40. 50. 60.] (6,)\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
    "               [10., 20., 30., 40., 50., 60.]])\n",
    "\n",
    "x_train = xy[0]\n",
    "y_train = xy[1]\n",
    "\n",
    "print(x_train, x_train.shape)\n",
    "print(y_train, y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. 경사 하강법 구현을 위해서 위에서 분리한 x_train 데이터와 계산될 weight, bias 값을 정의해보세요. 여기서 구현한 weight와 bias 는 linear regression 계산을 진행할시 직선의 기울기와 y 절편의 값이 됩니다.\n",
    "\n",
    "numpy 내의 random 함수를 이용해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8287997552952542 0.5207230021843172\n"
     ]
    }
   ],
   "source": [
    "beta_gd = np.random.uniform(low=-1.0, high=1.0)\n",
    "bias = np.random.uniform(low=-1.0, high=1.0)\n",
    "\n",
    "print(beta_gd, bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. 이제 최종적으로 linear regression을 경사하강법으로 학습하는 코드를 구현해봅시다. 경사하강법 구현을 위한 학습 Loop를 구현해보세요. 최종적으로 1000회 반복했을 시에 결과를 출력하세요.\n",
    "\n",
    "- 단, Error는 차이의 제곱을 이용해서 계산해주세요.\n",
    "- Gradient 값은 우리가 예측하는 각 변수에 대한 미분값입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://likethefirst.tistory.com/entry/Python-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95-%EC%BD%94%EB%94%A9%EC%9C%BC%EB%A1%9C-%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[1., 2., 3., 4., 5., 6.],\n",
    "               [10., 20., 30., 40., 50., 60.]])\n",
    "\n",
    "x_train = xy[0]\n",
    "y_train = xy[1]\n",
    "\n",
    "beta_gd = np.random.uniform(low=-1.0, high=1.0)\n",
    "bias = np.random.uniform(low=-1.0, high=1.0)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "for i in range(1000):\n",
    "    pass\n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch ([:10d]/1000 error: [:10f], beta_gd: [:10f]\".format(i, error, beta_gd.item(), bias.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d92db622cb5bb78c2c77e21c3317885bdf8c1e85044705cff7d629a77fb46d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
